{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_news_Classifier_using_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuAfqCuYCO8G",
        "outputId": "541fead5-3afa-4715-87a0-238360e43d43"
      },
      "source": [
        "#setting connection to google drive \n",
        "from google.colab import  drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN4OUDI9CTY6",
        "outputId": "33c78be5-0e95-4cc6-a055-3a3cc7c8fede"
      },
      "source": [
        "#changing the direcctory \n",
        "%cd \"/content/gdrive/MyDrive/fake news\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/fake news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGkiSN43CTdX",
        "outputId": "1a21fdbf-8ec4-428f-dc7e-34073f07fd5d"
      },
      "source": [
        "#libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,LSTM,Dropout,Embedding,Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.metrics import  confusion_matrix,accuracy_score\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JnpwntfvCTfm",
        "outputId": "87c693a8-777b-432b-a792-f98ed366d0ac"
      },
      "source": [
        "#view of data\n",
        "vocab_size=5000\n",
        "df=pd.read_csv(\"train.csv\")\n",
        "df[\"content\"]=df['author']+' '+df['title']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                            content\n",
              "0   0  ...  Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
              "1   1  ...  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
              "2   2  ...  Consortiumnews.com Why the Truth Might Get You...\n",
              "3   3  ...  Jessica Purkiss 15 Civilians Killed In Single ...\n",
              "4   4  ...  Howard Portnoy Iranian woman jailed for fictio...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrcpwmEJCTjB"
      },
      "source": [
        "#droppinf the na values\n",
        "df=df.dropna()\n",
        "df.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYl1QAfuCTqJ"
      },
      "source": [
        "# stemming and cleaning the data \n",
        "ps=PorterStemmer()\n",
        "corpus=[]\n",
        "for i in range(0, len(df)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['content'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwsYpn74ESf1"
      },
      "source": [
        "#one hot vector \n",
        "onehot_repr=[one_hot(words,vocab_size)for words in corpus] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIRBjLFSFIpD"
      },
      "source": [
        "#padding the sequence\n",
        "sent_length=30\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "y=df[\"label\"]\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMDtfQ2kFdHz"
      },
      "source": [
        "#defining the model lstm \n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,40,input_length=30))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss = BinaryCrossentropy(from_logits=True),metrics =\"accuracy\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCTgT1Uf6o6",
        "outputId": "a8ee9c01-b853-48cb-b199-9b7de8180d11"
      },
      "source": [
        "y=df[\"label\"]\n",
        "len(embedded_docs),y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18285, (18285,))"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM81ckNPFkB4",
        "outputId": "fafcd9ef-0530-45d8-ce7b-9dfafc4960bc"
      },
      "source": [
        "#fitiing the model\n",
        "calback=[EarlyStopping(monitor=\"val_loss\",min_delta=0.001,patience=5,verbose=1),\n",
        "         ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,patience=2,verbose=1),\n",
        "         ModelCheckpoint(\"classify.h5\",monitor=\"val_loss\",save_best_only=True)]\n",
        "history = model.fit(X_train, y_train, epochs = 25,batch_size = 128,validation_data = (X_test,y_test),callbacks = calback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4994: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 10s 80ms/step - loss: 0.3148 - accuracy: 0.8548 - val_loss: 0.0754 - val_accuracy: 0.9745\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 7s 77ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 0.0576 - val_accuracy: 0.9829\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 7s 76ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0663 - val_accuracy: 0.9798\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 7s 76ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0672 - val_accuracy: 0.9765\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 7s 76ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0635 - val_accuracy: 0.9833\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 7s 76ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0635 - val_accuracy: 0.9836\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0751 - val_accuracy: 0.9829\n",
            "Epoch 00007: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Antkovh6Vvyu",
        "outputId": "74dc8668-beed-4bc9-9b9d-a6fe1da8fd0e"
      },
      "source": [
        "# evaluating the test set \n",
        " model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 1s 8ms/step - loss: 0.0751 - accuracy: 0.9829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07510475814342499, 0.9829328656196594]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSegcdMWV9GD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36218714-8fa7-43b0-c2c7-2c1437d27233"
      },
      "source": [
        "p# predicting the values\n",
        "y_pred=model.predict_on_batch(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 308 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd9b4efc9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEyLVGHLW6lG",
        "outputId": "d0b8c800-2596-4b10-c955-552633dc97b2"
      },
      "source": [
        "# confusion matrix\n",
        "from tensorflow.math import round,confusion_matrix\n",
        "y_pred=round(y_pred)\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3366,   23],\n",
              "       [  80, 2566]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBEWtqgpjP8g"
      },
      "source": [
        " from tensorflow.keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OtjUeLyArw"
      },
      "source": [
        "#bidirectional lastm\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,40,input_length=30))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(optimizer=\"adam\", loss = BinaryCrossentropy(from_logits=True),metrics =\"accuracy\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E474hdDa4rA8",
        "outputId": "1f4da81b-6cff-4903-f9ac-315eb48da847"
      },
      "source": [
        "calback=[EarlyStopping(monitor=\"val_loss\",min_delta=0.001,patience=5,verbose=1),\n",
        "         ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,patience=2,verbose=1),\n",
        "         ModelCheckpoint(\"classify.h5\",monitor=\"val_loss\",save_best_only=True)]\n",
        "history = model.fit(X_train, y_train, epochs = 25,batch_size = 128,validation_data = (X_test,y_test),callbacks = calback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4994: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 17s 139ms/step - loss: 0.3137 - accuracy: 0.8437 - val_loss: 0.1004 - val_accuracy: 0.9635\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 12s 128ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.0594 - val_accuracy: 0.9793\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 12s 127ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0723 - val_accuracy: 0.9776\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 12s 128ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.0581 - val_accuracy: 0.9853\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 12s 129ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0636 - val_accuracy: 0.9836\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 12s 127ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0805 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 12s 126ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0704 - val_accuracy: 0.9871\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 12s 127ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0634 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 12s 127ms/step - loss: 3.5742e-04 - accuracy: 0.9999 - val_loss: 0.0700 - val_accuracy: 0.9862\n",
            "Epoch 00009: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftK8Mg_w4xdc",
        "outputId": "fee541d4-07bc-4424-ed80-ec3a2d5c0df4"
      },
      "source": [
        "y_pred=model.predict_on_batch(X_test)\n",
        "y_pred=round(y_pred)\n",
        "confusion_matrix(y_test,y_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 309 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd9b71b1710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3364,   25],\n",
              "       [  58, 2588]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_bJNIf7NOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}