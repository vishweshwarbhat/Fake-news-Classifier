{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Fake_news_Classifier_using_BOW_TFIDF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loIzJpgF0kxw",
        "outputId": "3384614d-77c7-48a9-9291-ba611dfe0d23"
      },
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frhgpOEY0mTb"
      },
      "source": [
        "import os \n",
        "os.environ[\"KAGGLE_CONFIG_DIR\"]=\"/content/gdrive/MyDrive/fake news/kaggle.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-srMl_Gc1HZ9",
        "outputId": "595b6af2-5d0c-4d9c-a157-27a2228f36da"
      },
      "source": [
        "%cd \"/content/gdrive/MyDrive/fake news\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/fake news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULTNcfvZ1qev"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "lvvUOjwcUr1x",
        "outputId": "be52a8e0-ae4a-40bb-a760-dfeee00dc412"
      },
      "source": [
        "df=pd.read_csv(\"train.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20800, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp5MWCaQVTLb",
        "outputId": "604e3dc1-7721-4680-bb2a-dc927364de59"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "title      558\n",
              "author    1957\n",
              "text        39\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oZXEFi5WU-b"
      },
      "source": [
        "df=df.dropna()\n",
        "df.reset_index(inplace=True)\n",
        "df[\"content\"]=df['author']+\" \"+df['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6T7rClRfS5K",
        "outputId": "b13999e2-cff3-4c4b-d641-860743d96ea0"
      },
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "stem=PorterStemmer()\n",
        "def stemming(content):\n",
        "    stemmed_content = re.sub('[^a-zA-Z]', ' ',content) # this basically replaces everything other than lower a-z & upper A-Z with a ' ', for eg apple,bananna --> apple bananna\n",
        "    stemmed_content = stemmed_content.lower() # to make all text lower case\n",
        "    stemmed_content = stemmed_content.split() # this basically splits the line into words with delimiter as ' '\n",
        "    stemmed_content = [stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] # basically remove all the stopwords and apply stemming to the final data\n",
        "    stemmed_content = ' '.join(stemmed_content) # this basically joins back and returns the cleaned sentence\n",
        "    return stemmed_content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "opIiedQFiUVe",
        "outputId": "23d50904-4c86-4615-d021-31620c4c91d6"
      },
      "source": [
        "df['content'] = df['content'].apply(stemming)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "      <td>darrel lucu hous dem aid even see comey letter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "      <td>daniel j flynn flynn hillari clinton big woman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>consortiumnew com truth might get fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "      <td>jessica purkiss civilian kill singl us airstri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "      <td>howard portnoy iranian woman jail fiction unpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  id  ... label                                            content\n",
              "0      0   0  ...     1  darrel lucu hous dem aid even see comey letter...\n",
              "1      1   1  ...     0  daniel j flynn flynn hillari clinton big woman...\n",
              "2      2   2  ...     1             consortiumnew com truth might get fire\n",
              "3      3   3  ...     1  jessica purkiss civilian kill singl us airstri...\n",
              "4      4   4  ...     1  howard portnoy iranian woman jail fiction unpu...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRxFCN0O4RqI"
      },
      "source": [
        "X = df['content'].values\n",
        "y = df['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfS3PB3bk5-E"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFhhdVelroz",
        "outputId": "36f8d7ad-4199-4165-90f0-c6d753b77243"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state = 0)\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "classifier = LogisticRegression(C = 100, penalty = 'l2', solver= 'newton-cg')\n",
        "classifier.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dlDhJEymVwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40be0df7-4ab2-4b57-8d11-056a4742465a"
      },
      "source": [
        "ypred=classifier.predict(x_test)\n",
        "accuracy_score(y_test,y_pred=ypred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9937106918238994"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHfEH26G7CtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21bf659-0710-4f44-a5d5-9e0e97f8e9ca"
      },
      "source": [
        "logit=LogisticRegression()\n",
        "knn=KNeighborsClassifier()\n",
        "rf=RandomForestClassifier()\n",
        "dt=DecisionTreeClassifier()\n",
        "mnb=MultinomialNB()\n",
        "xg=XGBClassifier()\n",
        "algorithms=[logit,knn,rf,dt,mnb,xg]\n",
        "\n",
        "for algorithm in algorithms:\n",
        "  algorithm.fit(x_train,y_train)\n",
        "  y_pred=algorithm.predict(x_test)\n",
        "  print(\"algorithm used\"+\" \"+str(algorithm))\n",
        "  print(confusion_matrix(y_test,y_pred=y_pred))\n",
        "  print(accuracy_score(y_test,y_pred=y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm used LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "[[2016   24]\n",
            " [  12 1605]]\n",
            "0.9901558654634947\n",
            "algorithm used KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "[[1112  928]\n",
            " [   3 1614]]\n",
            "0.7454197429587093\n",
            "algorithm used RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "[[2024   16]\n",
            " [   6 1611]]\n",
            "0.993984140005469\n",
            "algorithm used DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "[[2030   10]\n",
            " [  11 1606]]\n",
            "0.9942575881870386\n",
            "algorithm used MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "[[2027   13]\n",
            " [  82 1535]]\n",
            "0.9740224227508887\n",
            "algorithm used XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "[[1860  180]\n",
            " [  11 1606]]\n",
            "0.9477713973202079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65fwirlicEyW"
      },
      "source": [
        "X = df['content']\n",
        "y = df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a_rtS5EesSa"
      },
      "source": [
        "tfidf=TfidfVectorizer()\n",
        "x=tfidf.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfRl7ZcGfBW_",
        "outputId": "2670cf7e-814f-478b-af22-dc8d86d4becd"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state = 0)\n",
        "ogit=LogisticRegression()\n",
        "knn=KNeighborsClassifier()\n",
        "rf=RandomForestClassifier()\n",
        "dt=DecisionTreeClassifier()\n",
        "mnb=MultinomialNB()\n",
        "xg=XGBClassifier()\n",
        "algorithms=[logit,knn,rf,dt,mnb,xg]\n",
        "\n",
        "for algorithm in algorithms:\n",
        "  algorithm.fit(x_train,y_train)\n",
        "  y_pred=algorithm.predict(x_test)\n",
        "  print(\"algorithm used\"+\" \"+str(algorithm))\n",
        "  print(confusion_matrix(y_test,y_pred=y_pred))\n",
        "  print(accuracy_score(y_test,y_pred=y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm used LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "[[1985   55]\n",
            " [  16 1601]]\n",
            "0.9805851791085589\n",
            "algorithm used KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "[[  92 1948]\n",
            " [   0 1617]]\n",
            "0.4673229423024337\n",
            "algorithm used RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "[[2027   13]\n",
            " [   8 1609]]\n",
            "0.9942575881870386\n",
            "algorithm used DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "[[2029   11]\n",
            " [  16 1601]]\n",
            "0.992616899097621\n",
            "algorithm used MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "[[2036    4]\n",
            " [ 164 1453]]\n",
            "0.9540607054963085\n",
            "algorithm used XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "[[1869  171]\n",
            " [  11 1606]]\n",
            "0.9502324309543342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3u21pnfp2_z"
      },
      "source": [
        "## logitic regression is working so well so that we dont need any more hyper parameter optimization\n",
        "## Bag of Words giving better accuracy than the TF-IDF"
      ]
    }
  ]
}